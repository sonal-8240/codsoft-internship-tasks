{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2346296,"sourceType":"datasetVersion","datasetId":1416444}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.impute import SimpleImputer\nimport os\n\n# Path to the dataset\nfile_path = '/kaggle/input/imdb-india-movies/IMDb Movies India.csv'\n\n# Load the dataset with appropriate encoding\ndf = pd.read_csv(file_path, encoding='ISO-8859-1')\n\n# Data Cleaning\ndf = df.dropna(subset=['Rating'])\ndf['Votes'] = df['Votes'].str.replace(',', '').astype(float)\ndf['Year'] = df['Year'].str.extract(r'(\\d{4})').astype(float)\ndf['Duration'] = df['Duration'].str.replace(' min', '').astype(float)\n\n# Feature Engineering\ndf['21st_Century'] = (df['Year'] >= 2000).astype(int)\n\n# Fill missing values for numerical columns\nimputer = SimpleImputer(strategy='median')\ndf[['Year', 'Duration', 'Votes']] = imputer.fit_transform(df[['Year', 'Duration', 'Votes']])\n\n# Drop rows with missing values in key categorical columns\ndf = df.dropna(subset=['Genre', 'Director', 'Actor 1'])\n\n# One-hot encode 'Genre'\ndf = pd.concat([df, pd.get_dummies(df['Genre'], prefix='Genre')], axis=1)\n\n# Label encode categorical columns\nfor col in ['Director', 'Actor 1', 'Actor 2', 'Actor 3']:\n    df[col] = LabelEncoder().fit_transform(df[col])\n\n# Prepare features and target\nX = df.drop(['Rating', 'Name', 'Genre'], axis=1)\ny = df['Rating']\n\n# Handle any remaining NaN values\nX = X.fillna(X.median())\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Feature Scaling\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Define models\nrf = RandomForestRegressor(random_state=42)\ngbr = GradientBoostingRegressor(random_state=42)\n\n# Hyperparameter tuning with GridSearchCV\nparam_grid_rf = {\n    'n_estimators': [100, 200],\n    'max_depth': [None, 10, 20],\n    'min_samples_split': [2, 5]\n}\n\nparam_grid_gbr = {\n    'n_estimators': [100, 200],\n    'learning_rate': [0.01, 0.1],\n    'max_depth': [3, 5, 10]\n}\n\n# Grid search for RandomForest\ngrid_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\ngrid_rf.fit(X_train, y_train)\n\n# Grid search for GradientBoosting\ngrid_gbr = GridSearchCV(estimator=gbr, param_grid=param_grid_gbr, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\ngrid_gbr.fit(X_train, y_train)\n\n# Evaluate both models\nbest_rf = grid_rf.best_estimator_\nbest_gbr = grid_gbr.best_estimator_\n\n# Predictions\ny_pred_rf = best_rf.predict(X_test)\ny_pred_gbr = best_gbr.predict(X_test)\n\n# Evaluation Metrics\nrmse_rf = mean_squared_error(y_test, y_pred_rf, squared=False)\nr2_rf = r2_score(y_test, y_pred_rf)\n\nrmse_gbr = mean_squared_error(y_test, y_pred_gbr, squared=False)\nr2_gbr = r2_score(y_test, y_pred_gbr)\n\nprint(\"Random Forest RMSE:\", rmse_rf)\nprint(\"Random Forest R^2:\", r2_rf)\nprint(\"Gradient Boosting RMSE:\", rmse_gbr)\nprint(\"Gradient Boosting R^2:\", r2_gbr)\n\n# Feature importance for RandomForest\ntop_features_rf = X.columns[np.argsort(best_rf.feature_importances_)[::-1]]\nprint(\"Top Features (Random Forest):\", top_features_rf[:10])\n\n# Cross-validation scores\ncv_scores_rf = cross_val_score(best_rf, X, y, cv=5, scoring='neg_mean_squared_error')\ncv_scores_gbr = cross_val_score(best_gbr, X, y, cv=5, scoring='neg_mean_squared_error')\n\nprint(\"Random Forest CV RMSE:\", np.sqrt(-cv_scores_rf).mean())\nprint(\"Gradient Boosting CV RMSE:\", np.sqrt(-cv_scores_gbr).mean())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T07:25:09.409827Z","iopub.execute_input":"2024-08-14T07:25:09.410349Z","iopub.status.idle":"2024-08-14T07:37:39.806422Z","shell.execute_reply.started":"2024-08-14T07:25:09.410310Z","shell.execute_reply":"2024-08-14T07:37:39.804292Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Random Forest RMSE: 1.1373271888601988\nRandom Forest R^2: 0.3297408446931084\nGradient Boosting RMSE: 1.1334905762235683\nGradient Boosting R^2: 0.3342552666333356\nTop Features (Random Forest): Index(['Votes', 'Year', 'Duration', 'Actor 1', 'Actor 3', 'Actor 2',\n       'Director', 'Genre_Drama', 'Genre_Documentary', 'Genre_Action'],\n      dtype='object')\n","output_type":"stream"},{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]}]}